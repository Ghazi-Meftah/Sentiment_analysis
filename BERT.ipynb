{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XkSUlFBQDyb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "%matplotlib inline\n",
        "sns.set(color_codes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/code/ritwik002/1-6million-tweet-sentiment-analysis-using-bert/notebook"
      ],
      "metadata": {
        "id": "oAYI-QGMeGA_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-YVfn31U050",
        "outputId": "23aeb4c3-f34a-4f27-b109-882559f037e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Start by connecting gdrive into the google colab\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XspNH3gHQDyd"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/training.1600000.processed.noemoticon.csv', encoding='latin-1', header = None)\n",
        "df.columns=['Sentiment', 'id', 'Date', 'Query', 'User', 'Tweet']\n",
        "df = df.drop(columns=['id', 'Date', 'Query', 'User'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ajjh-5ObQDyg",
        "outputId": "8d43af07-be77-4e79-ef2c-2b3a9a43cde0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sentiment                                              Tweet\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0  @nationwideclass no, it's not behaving at all...."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfbe2d4b-d9bf-4544-aa91-89b33ac5a2be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfbe2d4b-d9bf-4544-aa91-89b33ac5a2be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cfbe2d4b-d9bf-4544-aa91-89b33ac5a2be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cfbe2d4b-d9bf-4544-aa91-89b33ac5a2be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "DqgvEpx-QDyh",
        "outputId": "a00a0015-4ae9-43b1-8f87-df4e7ce76005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0a1b19c850>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.countplot(df.Sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUlng-MrQDyj"
      },
      "outputs": [],
      "source": [
        "df['Sentiment'] = df.Sentiment.replace(4,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "CZ02VbMLQDyk",
        "outputId": "a6be8e88-2514-4a4f-db14-4bd51b60c7a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0a1a819cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.countplot(df.Sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_DYpHsPQDyl"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "hashtags = re.compile(r\"^#\\S+|\\s#\\S+\")\n",
        "mentions = re.compile(r\"^@\\S+|\\s@\\S+\")\n",
        "urls = re.compile(r\"https?://\\S+\")\n",
        "\n",
        "def process_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = hashtags.sub(' hashtag', text)\n",
        "    text = mentions.sub(' entity', text)\n",
        "    return text.strip().lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kw6G4iRqQDyn"
      },
      "outputs": [],
      "source": [
        "df['Tweet'] = df.Tweet.apply(process_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "O4sOBaZCQDyo",
        "outputId": "0f2e2314-e7bd-43e3-dae6-f4c44178090b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sentiment                                              Tweet\n",
              "0          0  entity  - awww, that's a bummer.  you shoulda ...\n",
              "1          0  is upset that he can't update his facebook by ...\n",
              "2          0  entity i dived many times for the ball. manage...\n",
              "3          0     my whole body feels itchy and like its on fire\n",
              "4          0  entity no, it's not behaving at all. i'm mad. ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09bf7d57-4908-4c28-a4cc-1d339eb82758\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>entity  - awww, that's a bummer.  you shoulda ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>entity i dived many times for the ball. manage...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>entity no, it's not behaving at all. i'm mad. ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09bf7d57-4908-4c28-a4cc-1d339eb82758')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09bf7d57-4908-4c28-a4cc-1d339eb82758 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09bf7d57-4908-4c28-a4cc-1d339eb82758');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEq1bONRQDyo"
      },
      "outputs": [],
      "source": [
        "labels = df.Sentiment.values\n",
        "text = df.Tweet.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfhStsBcWuqg",
        "outputId": "4543cf7c-8788-4d2a-964a-f85227a4be91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwxTWbtNQDyo"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer,BertForSequenceClassification,AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMIYoVmJQDyp"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByOO8JZ-QDyp",
        "outputId": "c26d93fd-0da0-4b5c-a6a7-95941c61314d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "input_ids = []\n",
        "attention_mask = []\n",
        "for i in text:\n",
        "    encoded_data = tokenizer.encode_plus(\n",
        "    i,\n",
        "    add_special_tokens=True,\n",
        "    max_length=64,\n",
        "    pad_to_max_length = True,\n",
        "    return_attention_mask= True,\n",
        "    return_tensors='pt')\n",
        "    input_ids.append(encoded_data['input_ids'])\n",
        "    attention_mask.append(encoded_data['attention_mask'])\n",
        "input_ids = torch.cat(input_ids,dim=0)\n",
        "attention_mask = torch.cat(attention_mask,dim=0)\n",
        "labels = torch.tensor(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBnIFr1WQDyp"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader,SequentialSampler,RandomSampler,TensorDataset,random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dO9cU8PpQDyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9cad45e-ecf1-49a7-be87-81c34fa66773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Size -  1280000\n",
            "Validation Size -  320000\n"
          ]
        }
      ],
      "source": [
        "dataset = TensorDataset(input_ids,attention_mask,labels)\n",
        "train_size = int(0.8*len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset,val_dataset = random_split(dataset,[train_size,val_size])\n",
        "\n",
        "print('Training Size - ',train_size)\n",
        "print('Validation Size - ',val_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6nQMpnGQDyq"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_dataset,sampler = RandomSampler(train_dataset),\n",
        "                     batch_size = 32)\n",
        "val_dl = DataLoader(val_dataset,sampler = SequentialSampler(val_dataset),\n",
        "                     batch_size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZE2hgZCuQDyq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af41c3b6-5b09-409b-9fb7-83031da7ba25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "len(train_dl),len(val_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4cc3u1fQDyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b456414f-2900-4a3d-f12d-75e6f1b473f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "'bert-base-uncased',\n",
        "num_labels = 2,\n",
        "output_attentions = False,\n",
        "output_hidden_states = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oHwC2xkQDyr"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVzEd3hXQDys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efdd5a38-4dc5-4fc0-8857-b783fc82ee18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN3nzQXjQDys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03b95ed8-2660-48a9-d3c2-666acb45a92b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(),lr = 2e-5,eps=1e-8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWMZcTwsQDyt"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 1\n",
        "total_steps = len(train_dl)*epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0,\n",
        "                                           num_training_steps=total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv4g9Q3UQDyt"
      },
      "outputs": [],
      "source": [
        "def accuracy(preds,labels):\n",
        "    pred_flat = np.argmax(preds,axis=1).flatten()\n",
        "    label_flat = labels.flatten()\n",
        "    return np.sum(pred_flat==label_flat)/len(label_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saHgi-nzQDyt"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloader_test):\n",
        "    model.eval()\n",
        "    loss_val_total = 0\n",
        "    predictions,true_vals = [],[]\n",
        "    for batch in dataloader_test:\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "            'input_ids':batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    loss_val_avg = loss_val_total / len(dataloader_test)\n",
        "    predictions = np.concatenate(predictions,axis=0)\n",
        "    true_vals = np.concatenate(true_vals,axis=0)\n",
        "    return loss_val_avg,predictions,true_vals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9pkvN9JQDyt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444,
          "referenced_widgets": [
            "60e9a870da9046cc960aa2596e8a8136",
            "43d8c4ced59f4874bdeee8f9f05bd68a",
            "df0e1a0cfdf8452da00582834bf1540a",
            "1f3a7f77080a431594e7f5c7cb81d8b9",
            "8dbeda11aa8247b49123ad88633084ad",
            "d79196bd645d41b5acafa6748018df5a",
            "edc33d4432a34d65a76e9aad1210d1f0",
            "64e9af8492214b0fbf0deb840ca95866",
            "735d8fc3855342578f61201697b9489c",
            "a34e2451f69c4c37a8ab4657f185894e",
            "0a2a2ca0aa2240bebc31b48258df859c",
            "205de18b506d402a9abc212dcc3194d5",
            "a03bea35669945d8864981e678a0504f",
            "4d9ef18478054b7d8c9be6f45a14d725",
            "34ee9b65781f40aa865af17f56512c8c",
            "a89e3bf12b49404eb95632a01fa3a7a0",
            "a68e6f7f535b4a20bca975f4d55900e3",
            "b717ba878d304bddbc380047d5b43c7a",
            "ab52c11657324abbb5595ee2cbba4fd1",
            "d94b1bd76af44e49a3b813135f1bd934",
            "28a1d58e7f0d4915b5234b70f8671597",
            "a343d5a522b245a394eccc5eaa13110e"
          ]
        },
        "outputId": "e5391082-fe91-4479-a112-146280873f61"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60e9a870da9046cc960aa2596e8a8136"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1:   0%|          | 0/40000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "205de18b506d402a9abc212dcc3194d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-5ff167400d3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                  }       \n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1567\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         )\n\u001b[0;32m-> 1021\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1022\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "torch.cuda.empty_cache()\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    loss_train_total = 0\n",
        "\n",
        "    progress_bar = tqdm(train_dl, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        model.zero_grad()\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }       \n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "         \n",
        "        \n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(train_dl)            \n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(val_dl)\n",
        "    val_acc = accuracy(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'Accuracy: {val_acc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBlMut0ZQDyu"
      },
      "outputs": [],
      "source": [
        "output_dir = './'\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOa3VtWVQDyv"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer,BertForSequenceClassification\n",
        "import torch\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "output_dir = './'\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "model_loaded = BertForSequenceClassification.from_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRubLQdMQDyz"
      },
      "outputs": [],
      "source": [
        "def Sentiment(sent):\n",
        "    output_dir = './'\n",
        "    tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "    model_loaded = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent, \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 64,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "        \n",
        "    input_id = encoded_dict['input_ids']\n",
        "\n",
        "    attention_mask = encoded_dict['attention_mask']\n",
        "    input_id = torch.LongTensor(input_id)\n",
        "    attention_mask = torch.LongTensor(attention_mask)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_loaded = model_loaded.to(device)\n",
        "    input_id = input_id.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model_loaded(input_id, token_type_ids=None, attention_mask=attention_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    index = logits.argmax()\n",
        "    return index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NARZ92mbQDy1"
      },
      "outputs": [],
      "source": [
        "ans = Sentiment('i want to die')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxkkhb2oQDy2"
      },
      "outputs": [],
      "source": [
        "if ans == 1:\n",
        "    print(\"Positive\")\n",
        "else:\n",
        "    print(\"Negative\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ett2vVvYQDy2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "60e9a870da9046cc960aa2596e8a8136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43d8c4ced59f4874bdeee8f9f05bd68a",
              "IPY_MODEL_df0e1a0cfdf8452da00582834bf1540a",
              "IPY_MODEL_1f3a7f77080a431594e7f5c7cb81d8b9"
            ],
            "layout": "IPY_MODEL_8dbeda11aa8247b49123ad88633084ad"
          }
        },
        "43d8c4ced59f4874bdeee8f9f05bd68a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d79196bd645d41b5acafa6748018df5a",
            "placeholder": "",
            "style": "IPY_MODEL_edc33d4432a34d65a76e9aad1210d1f0",
            "value": "  0%"
          }
        },
        "df0e1a0cfdf8452da00582834bf1540a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64e9af8492214b0fbf0deb840ca95866",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_735d8fc3855342578f61201697b9489c",
            "value": 0
          }
        },
        "1f3a7f77080a431594e7f5c7cb81d8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a34e2451f69c4c37a8ab4657f185894e",
            "placeholder": "",
            "style": "IPY_MODEL_0a2a2ca0aa2240bebc31b48258df859c",
            "value": " 0/1 [02:01&lt;?, ?it/s]"
          }
        },
        "8dbeda11aa8247b49123ad88633084ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d79196bd645d41b5acafa6748018df5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edc33d4432a34d65a76e9aad1210d1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64e9af8492214b0fbf0deb840ca95866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "735d8fc3855342578f61201697b9489c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a34e2451f69c4c37a8ab4657f185894e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a2a2ca0aa2240bebc31b48258df859c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "205de18b506d402a9abc212dcc3194d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a03bea35669945d8864981e678a0504f",
              "IPY_MODEL_4d9ef18478054b7d8c9be6f45a14d725",
              "IPY_MODEL_34ee9b65781f40aa865af17f56512c8c"
            ],
            "layout": "IPY_MODEL_a89e3bf12b49404eb95632a01fa3a7a0"
          }
        },
        "a03bea35669945d8864981e678a0504f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a68e6f7f535b4a20bca975f4d55900e3",
            "placeholder": "",
            "style": "IPY_MODEL_b717ba878d304bddbc380047d5b43c7a",
            "value": "Epoch 1:   0%"
          }
        },
        "4d9ef18478054b7d8c9be6f45a14d725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab52c11657324abbb5595ee2cbba4fd1",
            "max": 40000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d94b1bd76af44e49a3b813135f1bd934",
            "value": 6
          }
        },
        "34ee9b65781f40aa865af17f56512c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28a1d58e7f0d4915b5234b70f8671597",
            "placeholder": "",
            "style": "IPY_MODEL_a343d5a522b245a394eccc5eaa13110e",
            "value": " 6/40000 [02:01&lt;216:18:41, 19.47s/it, training_loss=0.234]"
          }
        },
        "a89e3bf12b49404eb95632a01fa3a7a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a68e6f7f535b4a20bca975f4d55900e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b717ba878d304bddbc380047d5b43c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab52c11657324abbb5595ee2cbba4fd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d94b1bd76af44e49a3b813135f1bd934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28a1d58e7f0d4915b5234b70f8671597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a343d5a522b245a394eccc5eaa13110e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}